# Stray Detector
Project created for Hack(her)413 2022

Dataset used : https://www.robots.ox.ac.uk/~vgg/data/pets/ 

This is a pet dataset by the Department of Engineering Science, University of Oxford. 

Main idea of this project is that :
1. This system will allow visually impaired or challenged people to detect any stray animals while walking on the walking tracks of the road.
2. This will also help self driving cars to detect any stray animals and thus save their lives

Algorithm used : Semantic Segmentation using FCN i.e MobileNet (Unet)

Paper Referred: https://www.researchgate.net/profile/Mostafa-Badawy/publication/321798038_Realtime_Semantic_Segmentation_Benchmarking_Framework/links/5a927635aca2721405649969/Realtime-Semantic-Segmentation-Benchmarking-Framework.pdf

Results : 
![PIC](https://user-images.githubusercontent.com/35986549/152685585-a8639892-2e33-49ee-b6e3-64accbdd6086.PNG)


![image](https://user-images.githubusercontent.com/35986549/152683516-3f2233c7-9a11-4b1f-873f-f12b4c9f1ed9.png)

The segmented area: 

![image](https://user-images.githubusercontent.com/35986549/152683536-ecf914b4-7289-4f5d-8efd-e95cce477516.png)


VIDEO : 
https://drive.google.com/file/d/1sWN6muvMwFR09zhqW7EMWr4A-5jOURWQ/view?usp=sharing

Future Scope :
This same methodology can be further used to aid Blind People to get full understanding of a scene and we could further provide speech explanation to them. 

This same methodology can also be used for self driving cars to understand the scenes and thus take locomotive actions based on it. (as described in the paper) 
